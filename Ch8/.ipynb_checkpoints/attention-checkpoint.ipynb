{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5, 1).repeat(4, axis=1)\n",
    "print(ar.shape)\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "a = np.random.randn(N, T)\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)\n",
    "# ar = a.reshape(N, T, 1) # 브로드캐스트를 사용하는 경우\n",
    "\n",
    "t = hs * ar\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ar = a.reshape(N, T, 1)#.repeat(T, axis=1)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "\n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "\n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "\n",
    "        return dhs, da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 4)\n",
      "(10, 5)\n",
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.layers import Softmax\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 10, 5, 4\n",
    "hs = np.random.randn(N, T, H)\n",
    "h = np.random.randn(N, H)\n",
    "hr = h.reshape(N, 1, H).repeat(T, axis=1)\n",
    "# hr = h.reshape(N, 1, H) # 브로드캐스트를 사용하는 경우\n",
    "\n",
    "t = hs * hr\n",
    "print(t.shape)\n",
    "\n",
    "s = np.sum(t, axis=2)\n",
    "print(s.shape)\n",
    "\n",
    "softmax = Softmax()\n",
    "a = softmax.forward(s)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import * # import numpy as np\n",
    "\n",
    "\n",
    "class AttentionWeight:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        hr = h.reshape(N, 1, H)#.repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "\n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "\n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "\n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAttention:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "\n",
    "\n",
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(2*H, V) / np.sqrt(2*H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.attention = TimeAttention()\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "        layers = [self.embed, self.lstm, self.attention, self.affine]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:,-1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        dec_hs = self.lstm.forward(out)\n",
    "        c = self.attention.forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.affine.forward(out)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2\n",
    "\n",
    "        dc, ddec_hs0 = dout[:,:,:H], dout[:,:,H:]\n",
    "        denc_hs, ddec_hs1 = self.attention.backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.lstm.backward(ddec_hs)\n",
    "        dh = self.lstm.dh\n",
    "        denc_hs[:, -1] += dh\n",
    "        self.embed.backward(dout)\n",
    "\n",
    "        return denc_hs\n",
    "\n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        h = enc_hs[:, -1]\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([sample_id]).reshape((1, 1))\n",
    "\n",
    "            out = self.embed.forward(x)\n",
    "            dec_hs = self.lstm.forward(out)\n",
    "            c = self.attention.forward(enc_hs, dec_hs)\n",
    "            out = np.concatenate((c, dec_hs), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(sample_id)\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.encoder.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionSeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        args = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = AttentionEncoder(*args)\n",
    "        self.decoder = AttentionDecoder(*args)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 1[s] | 손실 4.08\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 20[s] | 손실 3.09\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 41[s] | 손실 1.90\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 63[s] | 손실 1.72\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 83[s] | 손실 1.46\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 104[s] | 손실 1.19\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 125[s] | 손실 1.14\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 146[s] | 손실 1.09\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 167[s] | 손실 1.06\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 189[s] | 손실 1.04\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 210[s] | 손실 1.03\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 231[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 251[s] | 손실 1.02\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 271[s] | 손실 1.01\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 291[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 312[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 333[s] | 손실 1.00\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 354[s] | 손실 1.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 1978-08-11\n",
      "---\n",
      "정확도 0.000%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 1[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 22[s] | 손실 1.00\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 44[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 63[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 83[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 103[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 124[s] | 손실 0.99\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 144[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 165[s] | 손실 0.98\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 186[s] | 손실 0.97\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 206[s] | 손실 0.95\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 227[s] | 손실 0.94\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 248[s] | 손실 0.90\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 268[s] | 손실 0.83\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 288[s] | 손실 0.74\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 311[s] | 손실 0.66\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 332[s] | 손실 0.58\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 353[s] | 손실 0.46\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[91m☒\u001b[0m 2006-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[91m☒\u001b[0m 2007-08-09\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 1983-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 2016-11-08\n",
      "---\n",
      "정확도 51.680%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 1[s] | 손실 0.35\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 21[s] | 손실 0.30\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 42[s] | 손실 0.21\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 64[s] | 손실 0.14\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 87[s] | 손실 0.09\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 108[s] | 손실 0.07\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 128[s] | 손실 0.05\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 148[s] | 손실 0.04\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 169[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 190[s] | 손실 0.03\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 211[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 232[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 253[s] | 손실 0.02\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 273[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 294[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 315[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 335[s] | 손실 0.01\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 358[s] | 손실 0.01\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.900%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 1[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 23[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 43[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 64[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 84[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 105[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 128[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 149[s] | 손실 0.01\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 171[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 191[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 212[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 233[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 253[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 274[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 295[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 315[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 336[s] | 손실 0.00\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 356[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.900%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 1[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 43[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 64[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 87[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 107[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 129[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 147[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 168[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 189[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 210[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 232[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 253[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 274[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 295[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 317[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 338[s] | 손실 0.00\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 360[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 99.920%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 1[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 43[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 64[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 85[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 106[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 127[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 149[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 171[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 192[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 212[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 234[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 254[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 275[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 296[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 317[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 338[s] | 손실 0.00\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 360[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[91m☒\u001b[0m 1994-05-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[91m☒\u001b[0m 2013-08-22\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[91m☒\u001b[0m 2016-01-06\n",
      "---\n",
      "정확도 81.040%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 1[s] | 손실 0.11\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 23[s] | 손실 0.03\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 44[s] | 손실 0.01\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 65[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 86[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 107[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 127[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 149[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 169[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 190[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 212[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 232[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 253[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 273[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 294[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 315[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 336[s] | 손실 0.00\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 358[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 100.000%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 1[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 21[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 42[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 63[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 84[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 104[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 124[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 147[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 167[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 189[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 210[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 232[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 251[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 272[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 293[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 313[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 334[s] | 손실 0.00\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 355[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 100.000%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 1[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 22[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 43[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 64[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 86[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 105[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 126[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 148[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 169[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 190[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 211[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 221 / 351 | 시간 233[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 241 / 351 | 시간 254[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 261 / 351 | 시간 275[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 281 / 351 | 시간 296[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 301 / 351 | 시간 316[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 321 / 351 | 시간 337[s] | 손실 0.00\n",
      "| 에폭 9 |  반복 341 / 351 | 시간 358[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 100.000%\n",
      "| 에폭 10 |  반복 1 / 351 | 시간 1[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 21 / 351 | 시간 23[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 41 / 351 | 시간 44[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 61 / 351 | 시간 65[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 81 / 351 | 시간 86[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 101 / 351 | 시간 107[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 121 / 351 | 시간 127[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 141 / 351 | 시간 148[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 161 / 351 | 시간 169[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 181 / 351 | 시간 191[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 201 / 351 | 시간 212[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 221 / 351 | 시간 234[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 241 / 351 | 시간 256[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 261 / 351 | 시간 278[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 281 / 351 | 시간 298[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 301 / 351 | 시간 319[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 321 / 351 | 시간 342[s] | 손실 0.00\n",
      "| 에폭 10 |  반복 341 / 351 | 시간 364[s] | 손실 0.00\n",
      "Q 10/15/94                     \n",
      "T 1994-10-15\n",
      "\u001b[92m☑\u001b[0m 1994-10-15\n",
      "---\n",
      "Q thursday, november 13, 2008  \n",
      "T 2008-11-13\n",
      "\u001b[92m☑\u001b[0m 2008-11-13\n",
      "---\n",
      "Q Mar 25, 2003                 \n",
      "T 2003-03-25\n",
      "\u001b[92m☑\u001b[0m 2003-03-25\n",
      "---\n",
      "Q Tuesday, November 22, 2016   \n",
      "T 2016-11-22\n",
      "\u001b[92m☑\u001b[0m 2016-11-22\n",
      "---\n",
      "Q Saturday, July 18, 1970      \n",
      "T 1970-07-18\n",
      "\u001b[92m☑\u001b[0m 1970-07-18\n",
      "---\n",
      "Q october 6, 1992              \n",
      "T 1992-10-06\n",
      "\u001b[92m☑\u001b[0m 1992-10-06\n",
      "---\n",
      "Q 8/23/08                      \n",
      "T 2008-08-23\n",
      "\u001b[92m☑\u001b[0m 2008-08-23\n",
      "---\n",
      "Q 8/30/07                      \n",
      "T 2007-08-30\n",
      "\u001b[92m☑\u001b[0m 2007-08-30\n",
      "---\n",
      "Q 10/28/13                     \n",
      "T 2013-10-28\n",
      "\u001b[92m☑\u001b[0m 2013-10-28\n",
      "---\n",
      "Q sunday, november 6, 2016     \n",
      "T 2016-11-06\n",
      "\u001b[92m☑\u001b[0m 2016-11-06\n",
      "---\n",
      "정확도 100.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 50640 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54253 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 51221 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 54869 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.save_params of <__main__.AttentionSeq2seq object at 0x7f72082d7950>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('정확도 %.3f%%' % (acc * 100))\n",
    "\n",
    "\n",
    "model.save_params()\n",
    "\n",
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('에폭')\n",
    "plt.ylabel('정확도')\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.show()\n",
    "model.save_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKhklEQVR4nO3dz4ud53UH8O/x2JJxWlxIvYl/tDYYU7fg1BXuIlBoQ6jVRbyVFl0FtImhhm78V2QnKIKaUig2DVXAC1HTRSAUQrEkhIltFBSjYCl14hCw2xhjj/V0MaN6LI887yvd9+qM9fnABd97D4/OaMZfvTxzn/fUGCMA9HXHrW4AgC8mqAGaE9QAzQlqgOYENUBzdy6xaFXtu4+SbGxszKp/4oknJteePXt2bjvA7efXY4z7dnujlvh43n4M6nvvvXdW/TvvvDO59p577pm1to9MQk9VNbn2Bv4/PjPGOLTbG7Y+AJoT1ADNCWqA5gQ1QHOCGqA5QQ3Q3J5BXVUPVtUPq+qNqnq9qv5uHY0BsGXKgZfNJH8/xjhbVb+b5ExV/ccY442FewMgE66oxxj/PcY4u/3f/5PkzST3L90YAFtmHSGvqj9M8qdJ/muX944lObaatgC4anJQV9XvJPm3JM+NMd6/9v0xxokkJ7ZrnYEGWJFJn/qoqruyFdL/MsY4uWxLAOw05VMfleQfk7w5xvje8i0BsNOUK+pvJPnbJH9VVee2H3+zcF8AbNtzj3qM8Z9Jpt/bD4CVcjIRoDlBDdCcoAZoTlADNCeoAZpbZAr5fvTee+/Nqp8z5PLgwYOz1v7www9n1QPrcasGT7uiBmhOUAM0J6gBmhPUAM0JaoDmBDVAc4IaoLmpgwOerqrzVXWhqp5fuikAPjVlcMBGkuNJDid5PMnRqnp86cYA2DLlivqpJBfGGG+NMT5K8lKSZ5ZtC4CrpgT1/Une3vH80vZrn1FVx6rqdFWdXlVzAKzwXh+mkAMsY8oV9eUkD+54/sD2awCswZSgfjXJo1X1cFUdSHIkycvLtgXAVVOG225W1bNJXkmykeSFMcbri3cGQJKJe9RjjFNJTi3cCwC7cDIRoDlBDdCcoAZoTlADNGe47Q2aM7DWsFrgZriiBmhOUAM0J6gBmhPUAM0JaoDmBDVAc4IaoDlBDdCcKeQAzZlCDtCcKeQAzZlCDtCcKeQAzZlCDtCcKeQAzZlCDtBcjbH67eTbYY96zt9bVS3YCfAlcWaMcWi3N5xMBGhOUAM0J6gBmhPUAM2ZQn6DDhw4MLn2k08+mbX2xsbG3HaALzFX1ADNCWqA5gQ1QHOCGqA5QQ3QnKAGaE5QAzRnuC1Ac4bbAjRnuC1Ac4bbAjRnuC1Ac4bbAjRnuC1Ac4bbAjQ3aY96jHEqyamFewFgF04mAjQnqAGaE9QAzQlqgOYENUBzppDfoM3Nzcm1J0+enLX2nAnnnYzR50BqVU2uveOOedcrc77OK1euzFp77sT6OeZOt7/77rsn195557wo+eCDDybXfvzxx7PWnmPu9+dWcUUN0JygBmhOUAM0J6gBmhPUAM0JaoDmBDVAc4IaoDlBDdCcoAZobmVHyKvqWJJjq1oPgC2mkAM0N3nro6q+W1Xnth9fW7IpAD41+Yp6jHE8yfEFewFgF36ZCNCcoAZoTlADNCeoAZoT1ADNCWqA5gQ1QHO1xOToOScTH3roocnrXrp0aVYf+2XC8LXmTovm8+ZOFl9Kp5/BuZPCDx48OLn2wIEDc9uZbM409CR58sknJ9devHhx1tqvvfbarPqZzowxDu32Ro+fZgCuS1ADNCeoAZoT1ADNCWqA5gQ1QHOCGqC5SUFdVU9X1fmqulBVzy/dFACf2jOoq2ojWwMDDid5PMnRqnp86cYA2DLlivqpJBfGGG+NMT5K8lKSZ5ZtC4CrpgT1/Une3vH80vZrn1FVx6rqdFWdXlVzAJhCDtDelCvqy0ke3PH8ge3XAFiDKUH9apJHq+rhqjqQ5EiSl5dtC4Cr9tz6GGNsVtWzSV5JspHkhTHG64t3BkCSiXvUY4xTSU4t3AsAu3AyEaA5QQ3QnKAGaE5QAzS3yHDbQ4cOjdOnpx1QrKqV//kA+5DhtgD7laAGaE5QAzQnqAGaE9QAzQlqgOYENUBzghqguSnDbR+rqnM7Hu9X1XNr6A2ATLsf9fkkX0/+fyL55SQ/WLYtAK6au/XxzSQ/G2P8fIlmAPi8uUF9JMmLu72xcwr5u+++e/OdAZBkRlBvz0v8dpLv7/b+GOPEGOPQGOPQfffdt6r+AG57c66oDyc5O8b45VLNAPB5c4L6aK6z7QHAciYFdVV9Jcm3kpxcth0ArjV1Cvlvk3x14V4A2IWTiQDNCWqA5gQ1QHOCGqC5RaaQV9W4445p/wZcuXJl5X9+NxcvXpxV/8gjjyzTSDNL/OxdteR0+zlrz/0al/w7mWvO13nXXXfNWnvO17m5uTlr7aX6uJH6mUwhB9ivBDVAc4IaoDlBDdCcoAZoTlADNCeoAZoT1ADNCWqA5gQ1QHOT7kc9RVUdS3JsVesBsGVlQT3GOJHkRLJ1r49VrQtwu5szhfy7VXVu+/G1JZsC4FOTr6jHGMeTHF+wFwB24ZeJAM0JaoDmBDVAc4IaoDlBDdCcoAZoTlADNLfYFPKVL5r5E4CXnEQNsGKmkAPsV4IaoDlBDdCcoAZoTlADNCeoAZoT1ADN7RnUVfVCVf2qqn6yjoYA+KwpV9T/lOTphfsA4Dr2DOoxxo+S/GYNvQCwC1PIAZozhRygOZ/6AGhOUAM0N+XjeS8m+XGSx6rqUlV9Z/m2ALhqzz3qMcbRdTQCwO5sfQA0J6gBmhPUAM0JaoDmBDVAcys7mbgOc6eKz5labmI50JUraoDmBDVAc4IaoDlBDdCcoAZoTlADNCeoAZqbcpvTx6rq3I7H+1X13Bp6AyDTbnN6PsnXk6SqNpJcTvKDZdsC4Kq5Wx/fTPKzMcbPl2gGgM+be4T8SJIXd3vDFHKAZdTU+2FU1YEkv0jyx2OMX+5R22IKuXt9APvImTHGod3emLP1cTjJ2b1CGoDVmhPUR3OdbQ8AljMpqKvqK0m+leTksu0AcK1Jv0wcY/w2yVcX7gWAXTiZCNCcoAZoTlADNCeoAZoT1ADNLTWF/NdJrr0fyO9vvz7VnPpda7/gtOHae7H2vly7Uy/WXu/at6KXP7hu9RhjLY8kp5eqX3LtTr1Y2/fe2rff936MYesDoDtBDdDcOoP6xIL1S649t97aX56159Zb+8uz9tz6RXuZfJtTAG4NWx8AzQlqgOYWD+obnWJeVf9QVd/Yo+aFqvpVVf3kVveyXfd0VZ2vqgtV9fyqaoHb21r3qHdMMf/zsceA3Ko6l+TPxhiffEHNXyT53yT/PMb4k1vcy0aSn2brvt2Xkrya5OgY442bqQVY99bHpCnmVfVHSX76RcGYJGOMHyX5TYdekjyV5MIY460xxkdJXkryzApqgdvcuoP6ulPMr3E4yb/vs17uT/L2jueXtl+72VrgNre2oN6eYv7tJN+fUP7XWTCoO/UCsJd1XlFPmmJeVfck+b0xxi/2WS+Xkzy44/kD26/dbC1wm1tnUE+dYv6XSX64D3t5NcmjVfXw9hX7kSQvr6AWuM2tJahnTjGfvD9dVS8m+XGSx6rqUlV951b1MsbYTPJskleSvJnkX8cYr99sLUC7I+RVdTZbH5n7WC8ADYMagM9yhBygOUEN0JygBmhOUAM0J6gBmhPUAM39H6ZJ62q6fPlJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = \\\n",
    "    sequence.load_data('date.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 문장 반전\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "\n",
    "model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model.load_params()\n",
    "\n",
    "_idx = 0\n",
    "def visualize(attention_map, row_labels, column_labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax.patch.set_facecolor('black')\n",
    "    ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xticklabels(row_labels, minor=False)\n",
    "    ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "    global _idx\n",
    "    _idx += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "np.random.seed(1984)\n",
    "for _ in range(5):\n",
    "    idx = [np.random.randint(0, len(x_test))]\n",
    "    x = x_test[idx]\n",
    "    t = t_test[idx]\n",
    "\n",
    "    model.forward(x, t)\n",
    "    d = model.decoder.attention.attention_weights\n",
    "    d = np.array(d)\n",
    "    attention_map = d.reshape(d.shape[0], d.shape[2])\n",
    "\n",
    "    # 출력하기 위해 반전\n",
    "    attention_map = attention_map[:,::-1]\n",
    "    x = x[:,::-1]\n",
    "\n",
    "    row_labels = [id_to_char[i] for i in x[0]]\n",
    "    column_labels = [id_to_char[i] for i in t[0]]\n",
    "    column_labels = column_labels[1:]\n",
    "\n",
    "    visualize(attention_map, row_labels, column_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
